# vector_store_builder.py
import pandas as pd
import faiss
from sentence_transformers import SentenceTransformer
import os
import pickle

def build_and_save_vector_store(
    data_path: str, 
    text_column: str, 
    index_output_path: str,
    dataframe_output_path: str,
    model: SentenceTransformer
):
    """
    ì£¼ì–´ì§„ CSV íŒŒì¼ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ê³ , FAISS ì¸ë±ìŠ¤ì™€ ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì„ ì €ì¥í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ”„ '{data_path}' íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...")
    
    try:
        df = pd.read_csv(data_path)
        df[text_column] = df[text_column].fillna('')
        texts = df[text_column].tolist()
        
        if not texts:
            print(f"ğŸš¨ ê²½ê³ : '{data_path}'ì— ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"  - í…ìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ. ì´ {len(texts)}ê°œ í•­ëª© ì„ë² ë”© ì¤‘...")
        
        embeddings = model.encode(texts, convert_to_tensor=True, show_progress_bar=True)
        embeddings_np = embeddings.cpu().numpy()
        
        print(f"  - ì„ë² ë”© ì™„ë£Œ. ë²¡í„° ì°¨ì›: {embeddings_np.shape[1]}")
        
        index = faiss.IndexFlatL2(embeddings_np.shape[1])
        index.add(embeddings_np)
        
        print(f"  - FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ. ì¸ë±ìŠ¤ì— {index.ntotal}ê°œ ë²¡í„° í¬í•¨.")
        
        os.makedirs(os.path.dirname(index_output_path), exist_ok=True)
        faiss.write_index(index, index_output_path)
        
        with open(dataframe_output_path, 'wb') as f:
            pickle.dump(df, f)
            
        print(f"âœ… ì™„ë£Œ: ë²¡í„° DBëŠ” '{index_output_path}'ì—, ë°ì´í„°ëŠ” '{dataframe_output_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except FileNotFoundError:
        print(f"ğŸš¨ ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ '{data_path}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ğŸš¨ ì˜¤ë¥˜: ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ - {e}")

if __name__ == '__main__':
    print("â³ ì„ë² ë”© ëª¨ë¸(upskyy/bge-m3-korean) ë¡œë”© ì¤‘...")
    embedding_model = SentenceTransformer('upskyy/bge-m3-korean')
    print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

    # --- ìœ ë¬¼ ì •ë³´ ë²¡í„° DB êµ¬ì¶• ---
    build_and_save_vector_store(
        data_path=os.path.join('data', 'preprocessed_artifacts_final_with_images.csv'),
        text_column='rag_document',
        index_output_path=os.path.join('vector_store', 'artifacts.index'),
        dataframe_output_path=os.path.join('vector_store', 'artifacts_df.pkl'),
        model=embedding_model
    )
    
    print("-" * 50)

    # --- ì—­ì‚¬ ì •ë³´ ë²¡í„° DB êµ¬ì¶• ---
    build_and_save_vector_store(
        data_path=os.path.join('data', 'preprocessed_history_chunks_sectioned.csv'),
        text_column='text_chunk',
        index_output_path=os.path.join('vector_store', 'history.index'),
        dataframe_output_path=os.path.join('vector_store', 'history_df.pkl'),
        model=embedding_model
    )
